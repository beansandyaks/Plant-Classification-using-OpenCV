{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "62e74ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b02c925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Plant_Images'\n",
    "files=os.listdir(path)\n",
    "images=[]\n",
    "labels=[]\n",
    "aspect_ratios=[]\n",
    "variable=1\n",
    "var_=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "88be4336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of contours detected -> 82 \n",
      "Aspect ratio 3.8238993710691824\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_106.jpg\n",
      "No. of contours detected -> 102 \n",
      "Aspect ratio 3.625\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_108.jpg\n",
      "No. of contours detected -> 298 \n",
      "Aspect ratio 3.0199430199430197\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_110.jpg\n",
      "No. of contours detected -> 471 \n",
      "Aspect ratio 3.782857142857143\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_112.jpg\n",
      "No. of contours detected -> 91 \n",
      "Aspect ratio 2.419512195121951\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_114.jpg\n",
      "No. of contours detected -> 66 \n",
      "Aspect ratio 2.8819875776397517\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_116.jpg\n",
      "No. of contours detected -> 67 \n",
      "Aspect ratio 2.5511363636363638\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_118.jpg\n",
      "No. of contours detected -> 76 \n",
      "Aspect ratio 2.6698564593301435\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_120.jpg\n",
      "No. of contours detected -> 67 \n",
      "Aspect ratio 3.080745341614907\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_122.jpg\n",
      "No. of contours detected -> 66 \n",
      "Aspect ratio 3.9689922480620154\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_124.jpg\n",
      "No. of contours detected -> 86 \n",
      "Aspect ratio 2.7233009708737863\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_126.jpg\n",
      "No. of contours detected -> 68 \n",
      "Aspect ratio 3.55\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_128.jpg\n",
      "No. of contours detected -> 75 \n",
      "Aspect ratio 2.9166666666666665\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_130.jpg\n",
      "No. of contours detected -> 72 \n",
      "Aspect ratio 2.7604166666666665\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_132.jpg\n",
      "No. of contours detected -> 70 \n",
      "Aspect ratio 2.7572815533980584\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_134.jpg\n",
      "No. of contours detected -> 45 \n",
      "Aspect ratio 3.4518072289156625\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_136.jpg\n",
      "No. of contours detected -> 88 \n",
      "Aspect ratio 2.302521008403361\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_138.jpg\n",
      "No. of contours detected -> 74 \n",
      "Aspect ratio 3.2325581395348837\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_140.jpg\n",
      "No. of contours detected -> 66 \n",
      "Aspect ratio 2.30672268907563\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_142.jpg\n",
      "No. of contours detected -> 73 \n",
      "Aspect ratio 2.9585492227979273\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_144.jpg\n",
      "No. of contours detected -> 66 \n",
      "Aspect ratio 1.4593301435406698\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_146.jpg\n",
      "No. of contours detected -> 84 \n",
      "Aspect ratio 1.794871794871795\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_148.jpg\n",
      "No. of contours detected -> 61 \n",
      "Aspect ratio 1.807909604519774\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_150.jpg\n",
      "No. of contours detected -> 77 \n",
      "Aspect ratio 1.5841584158415842\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_152.jpg\n",
      "No. of contours detected -> 62 \n",
      "Aspect ratio 1.555023923444976\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_154.jpg\n",
      "No. of contours detected -> 78 \n",
      "Aspect ratio 1.2389705882352942\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_156.jpg\n",
      "No. of contours detected -> 86 \n",
      "Aspect ratio 1.4872881355932204\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_158.jpg\n",
      "No. of contours detected -> 82 \n",
      "Aspect ratio 1.5714285714285714\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_160.jpg\n",
      "No. of contours detected -> 72 \n",
      "Aspect ratio 1.2857142857142858\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_162.jpg\n",
      "No. of contours detected -> 49 \n",
      "Aspect ratio 1.40625\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_164.jpg\n",
      "No. of contours detected -> 83 \n",
      "Aspect ratio 1.4497607655502391\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_166.jpg\n",
      "No. of contours detected -> 68 \n",
      "Aspect ratio 1.4732142857142858\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_168.jpg\n",
      "No. of contours detected -> 59 \n",
      "Aspect ratio 1.7471264367816093\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_170.jpg\n",
      "No. of contours detected -> 113 \n",
      "Aspect ratio 1.5751295336787565\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_172.jpg\n",
      "No. of contours detected -> 95 \n",
      "Aspect ratio 1.4431372549019608\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_174.jpg\n",
      "No. of contours detected -> 90 \n",
      "Aspect ratio 1.7095435684647302\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_176.jpg\n",
      "No. of contours detected -> 60 \n",
      "Aspect ratio 1.6363636363636365\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_178.jpg\n",
      "No. of contours detected -> 67 \n",
      "Aspect ratio 1.5482233502538072\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_180.jpg\n",
      "No. of contours detected -> 92 \n",
      "Aspect ratio 1.7216494845360826\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_182.jpg\n",
      "No. of contours detected -> 70 \n",
      "Aspect ratio 1.4615384615384615\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_184.jpg\n",
      "No. of contours detected -> 147 \n",
      "Aspect ratio 1.1953125\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_186.jpg\n",
      "No. of contours detected -> 181 \n",
      "Aspect ratio 1.2526041666666667\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_188.jpg\n",
      "No. of contours detected -> 171 \n",
      "Aspect ratio 1.2678571428571428\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_190.jpg\n",
      "No. of contours detected -> 159 \n",
      "Aspect ratio 1.283132530120482\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_192.jpg\n",
      "No. of contours detected -> 146 \n",
      "Aspect ratio 1.0823529411764705\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_194.jpg\n",
      "No. of contours detected -> 147 \n",
      "Aspect ratio 0.9836601307189542\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_196.jpg\n",
      "No. of contours detected -> 186 \n",
      "Aspect ratio 1.0919881305637982\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_198.jpg\n",
      "No. of contours detected -> 233 \n",
      "Aspect ratio 1.0254957507082152\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_200.jpg\n",
      "No. of contours detected -> 170 \n",
      "Aspect ratio 1.2105263157894737\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_202.jpg\n",
      "No. of contours detected -> 240 \n",
      "Aspect ratio 1.2541899441340782\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_204.jpg\n",
      "No. of contours detected -> 166 \n",
      "Aspect ratio 1.2380952380952381\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_206.jpg\n",
      "No. of contours detected -> 196 \n",
      "Aspect ratio 1.3564954682779455\n",
      "D:\\AI_CW\\demo\\leaves\\leaf_208.jpg\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    if filename.endswith(('.JPG', '.jpg')):\n",
    "        image_name= os.path.join(path,filename)\n",
    "        image= cv.imread(image_name)\n",
    "\n",
    "        \n",
    "        #Extract label from file name\n",
    "        labels.append(filename)\n",
    "        \n",
    "        #Converting image to create binary image\n",
    "        image_hsv= cv.cvtColor(image,cv.COLOR_BGR2HSV)\n",
    "        \n",
    "        #Mask()\n",
    "        lower_green = np.array([52,0,55])\n",
    "        upper_green = np.array([104,255,255])\n",
    "        mask=cv.inRange(image_hsv,lower_green,upper_green)\n",
    "        \n",
    "        #Output after masking\n",
    "        output_hsv = image_hsv.copy()\n",
    "        output_hsv[np.where(mask==0)] = 0\n",
    "        \n",
    "        \n",
    "        #Conversion to grayscale\n",
    "        gray=cv.cvtColor(output_hsv,cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Histogram Equalization\n",
    "        equal_histogram = cv.equalizeHist(gray)\n",
    "\n",
    "        #Applying Gaussian Blur\n",
    "        blur= cv.GaussianBlur(gray,(3,3),0)\n",
    "        \n",
    "        \n",
    "        #Thresholding the image to create binary Image\n",
    "        ret,binary=cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        \n",
    "        file_name= 'D:\\AI_CW\\demo\\binary\\leaf_'+str(var_)+\".jpg\"\n",
    "        var_+=1\n",
    "        cv.imwrite(file_name,binary)\n",
    "      \n",
    "        \n",
    "        contours,_ = cv.findContours(binary,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        print(\"No. of contours detected -> %d \" %len(contours))\n",
    "        \n",
    "        contours= sorted(contours, key = cv.contourArea, reverse = True)[:1]\n",
    "        screen_contours = None\n",
    "        \n",
    "        for c in contours:\n",
    "            #Finding the bounding box of the leaf\n",
    "            x,y,w,h = cv.boundingRect(binary)\n",
    "            \n",
    "            #Drawing the bounding reactangle on the image\n",
    "            cv.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            \n",
    "            #Calculate the aspect ratio of the leaf\n",
    "            a_ratio =float(w)/h\n",
    "            \n",
    "\n",
    "            print(\"Aspect ratio\",a_ratio)\n",
    "            aspect_ratios.append(aspect_ratio)\n",
    "    \n",
    "        \n",
    "        file_name= 'D:\\AI_CW\\demo\\leaves\\leaf_'+str(variable)+\".jpg\"\n",
    "        print(file_name)\n",
    "        variable+=1\n",
    "        cv.imwrite(file_name,image)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b6f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "188e3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = labels\n",
    "y = aspect_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5b1c15ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0001_0014.jpg',\n",
       " '0001_0015.jpg',\n",
       " '0001_0018.jpg',\n",
       " '0001_0019.jpg',\n",
       " '0001_0027.jpg',\n",
       " '0001_0039.jpg',\n",
       " '0001_0040.jpg',\n",
       " '0001_0045.jpg',\n",
       " '0001_0055.jpg',\n",
       " '0001_0075.jpg',\n",
       " '0001_0077.jpg',\n",
       " '0001_0079.jpg',\n",
       " '0001_0087.jpg',\n",
       " '0001_0099.jpg',\n",
       " '0001_0115.jpg',\n",
       " '0001_0127.jpg',\n",
       " '0001_0130.jpg',\n",
       " '0001_0155.jpg',\n",
       " '0001_0157.jpg',\n",
       " '0001_0158.jpg',\n",
       " '0008_0001.jpg',\n",
       " '0008_0002.jpg',\n",
       " '0008_0003.jpg',\n",
       " '0008_0004.jpg',\n",
       " '0008_0005.jpg',\n",
       " '0008_0006.jpg',\n",
       " '0008_0007.jpg',\n",
       " '0008_0008.jpg',\n",
       " '0008_0009.jpg',\n",
       " '0008_0010.jpg',\n",
       " '0008_0011.jpg',\n",
       " '0008_0012.jpg',\n",
       " '0008_0013.jpg',\n",
       " '0008_0014.jpg',\n",
       " '0008_0015.jpg',\n",
       " '0008_0016.jpg',\n",
       " '0008_0017.jpg',\n",
       " '0008_0018.jpg',\n",
       " '0008_0019.jpg',\n",
       " '0008_0020.jpg',\n",
       " '0011_0004.jpg',\n",
       " '0011_0005.jpg',\n",
       " '0011_0006.jpg',\n",
       " '0011_0007.jpg',\n",
       " '0011_0008.jpg',\n",
       " '0011_0009.jpg',\n",
       " '0011_0010.jpg',\n",
       " '0011_0011.jpg',\n",
       " '0011_0012.jpg',\n",
       " '0011_0013.jpg',\n",
       " '0011_0014.jpg',\n",
       " '0011_0017.jpg']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6c1f509b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455'),\n",
       " Decimal('1.3564954682779455')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b261cab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split data into Training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7,random_state=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c3d4eb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 16)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b7a02309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=1)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6a5245ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0008_0003.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [156]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:327\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 327\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '0008_0003.jpg'"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472ce7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81bdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8333e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
